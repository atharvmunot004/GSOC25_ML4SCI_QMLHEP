{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task II: Classical Graph Neural Network (GNN) \n",
    "## For Task II, you will use ParticleNet’s data for Quark/Gluon jet classification available [here](https://zenodo.org/records/3164691#.YigdGt9MHrB) with its corresponding description. \n",
    "<ul>\n",
    "    <li> Choose 2 Graph-based architectures of your choice to classify jets as being quarks or gluons. Provide a description on what considerations you have taken to project this point-cloud dataset to a set of interconnected nodes and edges.\n",
    "    <li> Discuss the resulting performance of the 2 chosen architectures. \n",
    "</ul>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'y']\n",
      "Item:\n",
      "X\n",
      "Data[Item]\n",
      "Dimension: 3\n",
      "[[[ 6.21580243e-01 -8.49013586e-01  5.02133119e+00 -2.11000000e+02]\n",
      "  [ 6.41751806e-01 -1.25072426e+00  5.44050034e+00  2.11000000e+02]\n",
      "  [ 2.01318448e-01 -9.03872384e-01  4.90318847e+00  2.20000000e+01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 3.56561010e-01  1.28450604e+00  1.74690075e+00  2.20000000e+01]\n",
      "  [ 1.64376978e-01  1.34179128e+00  1.62318700e+00  2.20000000e+01]\n",
      "  [ 4.29715184e+00  1.00013501e+00  1.88439142e+00  1.30000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 1.08500898e+01  1.05767017e+00  6.35388683e+00 -2.11000000e+02]\n",
      "  [ 4.13482156e-02  7.46948660e-01  6.13804598e+00  2.20000000e+01]\n",
      "  [ 5.16705560e-01  1.14248976e+00  6.33461836e+00 -2.11000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3.65098368e-01 -6.30028387e-01  6.58745282e+00  2.20000000e+01]\n",
      "  [ 5.82179999e-01 -5.93970848e-01  5.93824615e+00  2.11000000e+02]\n",
      "  [ 8.70825542e-01 -6.85617630e-01  5.97198619e+00 -2.11000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 2.94381463e-01 -7.25735015e-01  5.50873569e+00  2.20000000e+01]\n",
      "  [ 1.34087798e+00 -7.29881843e-01  5.50888453e+00 -3.21000000e+02]\n",
      "  [ 6.32790901e+00 -7.15341122e-01  5.51705428e+00  1.30000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 2.65977826e+00  8.02494340e-01  3.20426987e+00  2.11000000e+02]\n",
      "  [ 1.81350610e+00  7.50877903e-01  3.26367324e+00  2.20000000e+01]\n",
      "  [ 1.53513343e-01  1.32260575e+00  3.45010304e+00  2.11000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
      "Shape:\n",
      "(100000, 134, 4)\n",
      "Item:\n",
      "y\n",
      "Data[Item]\n",
      "Dimension: 1\n",
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "Shape:\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import load\n",
    "\n",
    "data = load('ParticleNet_jetClassification\\\\QG_jets_1.npz')\n",
    "lst = data.files\n",
    "print (lst)\n",
    "for item in lst:\n",
    "    print(\"Item:\")\n",
    "    print(item)\n",
    "    print (\"Data[Item]\")\n",
    "    print (f\"Dimension: {np.ndim(data[item])}\")\n",
    "    print(data[item])\n",
    "    print (\"Shape:\")\n",
    "    print (data[item].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'y']\n",
      "Item:\n",
      "X\n",
      "Data[Item]\n",
      "Dimension: 3\n",
      "[[[ 3.93203966e-01  3.50858538e-01  8.55396185e-01  2.20000000e+01]\n",
      "  [ 2.46338260e+00  1.65702215e-01  7.61525307e-01  2.20000000e+01]\n",
      "  [ 2.56550934e+00 -5.68774857e-02  7.89741416e-01  2.11000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 1.61694863e+00 -1.31621717e+00  9.98804499e-01 -2.11000000e+02]\n",
      "  [ 1.58885285e-01 -1.51184963e+00  9.30179606e-01  2.20000000e+01]\n",
      "  [ 1.91738285e+00 -1.84739871e+00  1.31081899e+00 -3.21000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 9.02373553e-01  1.26997967e+00  3.01591217e+00  3.21000000e+02]\n",
      "  [ 7.52902861e-02  9.00624519e-01  3.43656410e+00  2.20000000e+01]\n",
      "  [ 5.31198316e-01  1.16975047e+00  3.28990387e+00  2.11000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.42832333e-02 -2.46208974e-01  2.17259328e+00  2.20000000e+01]\n",
      "  [ 1.32675426e-01 -4.28298145e-01  2.85323286e+00  2.20000000e+01]\n",
      "  [ 1.20109483e-01 -4.96853995e-01  2.19714075e+00  2.20000000e+01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 6.64028114e-01 -2.48153084e-01  3.81776810e+00 -2.11000000e+02]\n",
      "  [ 6.14624836e-01 -3.50465095e-01  3.80802685e+00  2.11000000e+02]\n",
      "  [ 1.56733660e+00 -4.72029324e-01  3.17529917e+00  2.11000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 4.45111252e-01  6.86026633e-01  5.62889137e-02  2.20000000e+01]\n",
      "  [ 2.21785352e-01  3.34816960e-01  5.70924630e-01  2.20000000e+01]\n",
      "  [ 1.47769453e+00  7.42232672e-02 -1.18604209e-02 -2.11000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
      "Shape:\n",
      "(100000, 132, 4)\n",
      "Item:\n",
      "y\n",
      "Data[Item]\n",
      "Dimension: 1\n",
      "[1. 1. 1. ... 1. 1. 0.]\n",
      "Shape:\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import load\n",
    "\n",
    "data = load('ParticleNet_jetClassification\\\\QG_jets_2.npz')\n",
    "lst = data.files\n",
    "print (lst)\n",
    "for item in lst:\n",
    "    print(\"Item:\")\n",
    "    print(item)\n",
    "    print (\"Data[Item]\")\n",
    "    print (f\"Dimension: {np.ndim(data[item])}\")\n",
    "    print(data[item])\n",
    "    print (\"Shape:\")\n",
    "    print (data[item].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'y']\n",
      "Item:\n",
      "X\n",
      "Data[Item]\n",
      "Dimension: 3\n",
      "[[[ 4.07201237e+00  1.09956405e+00  3.85282264e+00  2.11000000e+02]\n",
      "  [ 7.73380167e-01  7.13987483e-01  3.68545357e+00 -2.11000000e+02]\n",
      "  [ 1.14809578e-01  5.78924014e-01  3.74063251e+00  2.20000000e+01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 2.39305753e+00  1.12300153e+00  6.36019987e+00 -2.11000000e+02]\n",
      "  [ 2.96587205e+00  8.59178845e-01  6.37095677e+00  2.11000000e+02]\n",
      "  [ 4.78190822e+00  7.45407187e-01  6.31373908e+00  1.30000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 6.74573195e-01  1.02391768e+00  2.14886551e+00  2.11000000e+02]\n",
      "  [ 3.37872916e+00  5.89779017e-01  2.07253851e+00 -2.21200000e+03]\n",
      "  [ 1.56140940e+00  1.00366747e+00  2.25537923e+00  2.20000000e+01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.96117783e+00  5.69513955e-01  1.43561827e+00  2.20000000e+01]\n",
      "  [ 1.76964996e+00 -1.71362996e-02  1.74397455e+00 -2.11000000e+02]\n",
      "  [ 6.10189208e+00  1.21070340e-02  1.75584304e+00  3.21000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 6.15951895e-01 -9.18019797e-01  1.24508523e+00  2.20000000e+01]\n",
      "  [ 5.08260657e+00 -1.57286044e+00  1.11430625e+00  3.21000000e+02]\n",
      "  [ 7.46450907e+00 -1.55764155e+00  1.05315625e+00  2.20000000e+01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 1.48603101e-01 -1.03610904e+00  4.30775965e+00  2.20000000e+01]\n",
      "  [ 3.69540769e-01 -9.40924431e-01  4.65645666e+00  2.11000000e+02]\n",
      "  [ 6.78110748e-01 -1.54770870e+00  4.86939633e+00  2.20000000e+01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
      "Shape:\n",
      "(100000, 128, 4)\n",
      "Item:\n",
      "y\n",
      "Data[Item]\n",
      "Dimension: 1\n",
      "[0. 1. 0. ... 0. 0. 1.]\n",
      "Shape:\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import load\n",
    "\n",
    "data = load('ParticleNet_jetClassification\\\\QG_jets_3.npz')\n",
    "lst = data.files\n",
    "print (lst)\n",
    "for item in lst:\n",
    "    print(\"Item:\")\n",
    "    print(item)\n",
    "    print (\"Data[Item]\")\n",
    "    print (f\"Dimension: {np.ndim(data[item])}\")\n",
    "    print(data[item])\n",
    "    print (\"Shape:\")\n",
    "    print (data[item].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'y']\n",
      "Item:\n",
      "X\n",
      "Data[Item]\n",
      "Dimension: 3\n",
      "[[[ 9.86502732e-01 -1.35386410e+00  2.64458483e-01  2.20000000e+01]\n",
      "  [ 1.05703896e+00 -1.34115771e+00  2.19554508e-01  2.21200000e+03]\n",
      "  [ 6.21758834e-01 -1.29731387e+00  2.74126482e-01  2.20000000e+01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 2.25822279e+00 -8.77790734e-01  4.93749866e+00 -2.11000000e+02]\n",
      "  [ 1.05114111e+01 -1.06668930e+00  5.34817384e+00  2.11200000e+03]\n",
      "  [ 4.82717145e+00 -1.06442943e+00  5.25285614e+00 -2.11000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 1.39930755e-01  1.25928787e+00  1.70230491e+00  2.20000000e+01]\n",
      "  [ 6.17137998e-01  1.64929615e+00  1.96346964e+00  2.20000000e+01]\n",
      "  [ 5.70673135e-01  1.84701626e+00  1.89809982e+00 -2.11000000e+02]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.45050443e+00  8.93212584e-01  2.75104519e+00 -2.11000000e+02]\n",
      "  [ 6.18814307e-02  2.97050993e-01  2.42893994e+00  2.11000000e+02]\n",
      "  [ 8.55867110e-01  7.21385896e-01  2.97491929e+00  2.20000000e+01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 3.42364412e+00  1.91124060e+00  3.57532950e+00  2.11000000e+02]\n",
      "  [ 1.66703991e-01  1.62315844e+00  3.04744259e+00  2.20000000e+01]\n",
      "  [ 2.82207572e+00  1.89861351e+00  3.30448989e+00  2.21200000e+03]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 1.40541704e+00 -8.05061377e-01  1.79024133e+00 -2.11000000e+02]\n",
      "  [ 5.57270930e-01 -2.58368281e-01  1.29400867e+00  2.11000000e+02]\n",
      "  [ 1.21089110e+00 -8.88822296e-01  1.48453429e+00  2.20000000e+01]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
      "Shape:\n",
      "(100000, 134, 4)\n",
      "Item:\n",
      "y\n",
      "Data[Item]\n",
      "Dimension: 1\n",
      "[0. 0. 0. ... 1. 0. 0.]\n",
      "Shape:\n",
      "(100000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import load\n",
    "\n",
    "data = load('ParticleNet_jetClassification\\\\QG_jets_withbc_0.npz')\n",
    "lst = data.files\n",
    "print (lst)\n",
    "for item in lst:\n",
    "    print(\"Item:\")\n",
    "    print(item)\n",
    "    print (\"Data[Item]\")\n",
    "    print (f\"Dimension: {np.ndim(data[item])}\")\n",
    "    print(data[item])\n",
    "    print (\"Shape:\")\n",
    "    print (data[item].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vmuno\\OneDrive\\Desktop\\GSOC25\\GSOC25\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (4288) to match target batch_size (32).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m20\u001b[39m):  \u001b[38;5;66;03m# Reduce epochs for testing; increase as needed\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m     acc = test()\n\u001b[32m     87\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     63\u001b[39m optimizer.zero_grad()\n\u001b[32m     64\u001b[39m out = model(batch)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m loss.backward()\n\u001b[32m     67\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vmuno\\OneDrive\\Desktop\\GSOC25\\GSOC25\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vmuno\\OneDrive\\Desktop\\GSOC25\\GSOC25\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vmuno\\OneDrive\\Desktop\\GSOC25\\GSOC25\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1295\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1294\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vmuno\\OneDrive\\Desktop\\GSOC25\\GSOC25\\Lib\\site-packages\\torch\\nn\\functional.py:3494\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3493\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3494\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3495\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3498\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3501\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: Expected input batch_size (4288) to match target batch_size (32)."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = np.load('ParticleNet_jetClassification\\\\QG_jets_1.npz')\n",
    "node_features = data['X']  # Shape: (100000, M, 4)\n",
    "labels = data['y']  # Shape: (100000,)\n",
    "\n",
    "# Define a function to create edges (fully connected graph for simplicity)\n",
    "def create_edge_index(num_nodes):\n",
    "    row = []\n",
    "    col = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i != j:  # Avoid self-loops\n",
    "                row.append(i)\n",
    "                col.append(j)\n",
    "    return torch.tensor([row, col], dtype=torch.long)\n",
    "\n",
    "# Convert dataset into a list of graphs\n",
    "graphs = []\n",
    "for i in range(len(node_features)):\n",
    "    x = torch.tensor(node_features[i], dtype=torch.float)  # Node features for jet i\n",
    "    y = torch.tensor(labels[i], dtype=torch.long)  # Label for jet i\n",
    "    edge_index = create_edge_index(x.shape[0])  # Fully connected graph\n",
    "    graphs.append(Data(x=x, edge_index=edge_index, y=y))\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "batch_size = 32\n",
    "loader = DataLoader(graphs, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Step 2: Define the GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Step 3: Initialize the model, optimizer, and loss function\n",
    "input_dim = 4  # Each particle has 4 features: pt, rapidity, azimuthal angle, pdgid\n",
    "hidden_dim = 64\n",
    "output_dim = 2  # Binary classification: quark (1) or gluon (0)\n",
    "\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 4: Train the model\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in loader:\n",
    "        out = model(batch)\n",
    "        _, pred = out.max(dim=1)\n",
    "        correct += pred.eq(batch.y).sum().item()\n",
    "        total += batch.y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):  # Reduce epochs for testing; increase as needed\n",
    "    loss = train()\n",
    "    acc = test()\n",
    "    print(f'Epoch {epoch}, Loss: {loss:.4f}, Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vmuno\\OneDrive\\Desktop\\GSOC25\\GSOC25\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6141, Accuracy: 0.6756\n",
      "Epoch 1, Loss: 0.6041, Accuracy: 0.6745\n",
      "Epoch 2, Loss: 0.6039, Accuracy: 0.6853\n",
      "Epoch 3, Loss: 0.6035, Accuracy: 0.6838\n",
      "Epoch 4, Loss: 0.6031, Accuracy: 0.6813\n",
      "Epoch 5, Loss: 0.6021, Accuracy: 0.6770\n",
      "Epoch 6, Loss: 0.6032, Accuracy: 0.6543\n",
      "Epoch 7, Loss: 0.6035, Accuracy: 0.6721\n",
      "Epoch 8, Loss: 0.6028, Accuracy: 0.6698\n",
      "Epoch 9, Loss: 0.6028, Accuracy: 0.6705\n",
      "Epoch 10, Loss: 0.6024, Accuracy: 0.6729\n",
      "Epoch 11, Loss: 0.6033, Accuracy: 0.6739\n",
      "Epoch 12, Loss: 0.6028, Accuracy: 0.6756\n",
      "Epoch 13, Loss: 0.6033, Accuracy: 0.6849\n",
      "Epoch 14, Loss: 0.6038, Accuracy: 0.6822\n",
      "Epoch 15, Loss: 0.6037, Accuracy: 0.6845\n",
      "Epoch 16, Loss: 0.6027, Accuracy: 0.6822\n",
      "Epoch 17, Loss: 0.6029, Accuracy: 0.6574\n",
      "Epoch 18, Loss: 0.6029, Accuracy: 0.6834\n",
      "Epoch 19, Loss: 0.6034, Accuracy: 0.6845\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Step 1: Load the data\n",
    "data = np.load('ParticleNet_jetClassification\\\\QG_jets_1.npz')\n",
    "node_features = data['X']  # Shape: (100000, M, 4)\n",
    "labels = data['y']  # Shape: (100000,)\n",
    "\n",
    "# Define a function to create edges (fully connected graph for simplicity)\n",
    "def create_edge_index(num_nodes):\n",
    "    row = []\n",
    "    col = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i != j:  # Avoid self-loops\n",
    "                row.append(i)\n",
    "                col.append(j)\n",
    "    return torch.tensor([row, col], dtype=torch.long)\n",
    "\n",
    "# Convert dataset into a list of graphs\n",
    "graphs = []\n",
    "for i in range(len(node_features)):\n",
    "    x = torch.tensor(node_features[i], dtype=torch.float)  # Node features for jet i\n",
    "    y = torch.tensor(labels[i], dtype=torch.long)  # Label for jet i\n",
    "    edge_index = create_edge_index(x.shape[0])  # Fully connected graph\n",
    "    graphs.append(Data(x=x, edge_index=edge_index, y=y))\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "batch_size = 32\n",
    "loader = DataLoader(graphs, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Step 2: Define the GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)  # Fully connected layer for graph-level classification\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)  # Aggregate node features into graph-level features\n",
    "        x = self.fc(x)  # Final classification layer\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Step 3: Initialize the model, optimizer, and loss function\n",
    "input_dim = 4  # Each particle has 4 features: pt, rapidity, azimuthal angle, pdgid\n",
    "hidden_dim = 64\n",
    "output_dim = 2  # Binary classification: quark (1) or gluon (0)\n",
    "\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 4: Train the model\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)  # Output shape: (batch_size, output_dim)\n",
    "        loss = criterion(out, batch.y)  # batch.y shape: (batch_size,)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in loader:\n",
    "        out = model(batch)\n",
    "        _, pred = out.max(dim=1)\n",
    "        correct += pred.eq(batch.y).sum().item()\n",
    "        total += batch.y.size(0)\n",
    "    return correct / total\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):  # Reduce epochs for testing; increase as needed\n",
    "    loss = train()\n",
    "    acc = test()\n",
    "    print(f'Epoch {epoch}, Loss: {loss:.4f}, Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to gcn_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model locally\n",
    "torch.save(model.state_dict(), 'gcn_model.pth')  # Save only the model's parameters\n",
    "print(\"Model saved to gcn_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a **line-by-line breakdown** of the code:\n",
    "\n",
    "---\n",
    "\n",
    "### **Imports**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **`numpy`**: Used to load and manipulate the `.npz` dataset.\n",
    "2. **`torch`**: Core PyTorch library for defining and training models.\n",
    "3. **`torch_geometric.data.Data`**: Represents a single graph with nodes, edges, and features.\n",
    "4. **`torch_geometric.data.DataLoader`**: Handles batching and shuffling of multiple graphs.\n",
    "5. **`torch_geometric.nn.GCNConv`**: Implements a Graph Convolutional Network (GCN) layer.\n",
    "6. **`torch_geometric.nn.global_mean_pool`**: Aggregates node features into a single graph-level representation.\n",
    "7. **`torch.nn.functional`**: Provides activation functions like `relu` and `log_softmax`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Load the Data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('ParticleNet_jetClassification\\\\QG_jets_1.npz')\n",
    "node_features = data['X']  # Shape: (100000, M, 4)\n",
    "labels = data['y']  # Shape: (100000,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **`np.load`**: Loads the `.npz` file containing the dataset.\n",
    "9. **`node_features`**: Extracts the particle-level features for each jet. Shape `(100000, M, 4)`:\n",
    "   - `100000`: Number of jets.\n",
    "   - `M`: Maximum number of particles in a jet (zero-padded).\n",
    "   - `4`: Features per particle (`pt`, `rapidity`, `azimuthal angle`, `pdgid`).\n",
    "10. **`labels`**: Extracts the jet-level labels (`0` for gluon, `1` for quark). Shape `(100000,)`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Define a Function to Create Edges**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge_index(num_nodes):\n",
    "    row = []\n",
    "    col = []\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i != j:  # Avoid self-loops\n",
    "                row.append(i)\n",
    "                col.append(j)\n",
    "    return torch.tensor([row, col], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. **`create_edge_index`**: Creates a fully connected graph for a jet:\n",
    "    - **`row` and `col`**: Define the source and target nodes for each edge.\n",
    "    - **`i != j`**: Avoids self-loops (edges from a node to itself).\n",
    "12. **`torch.tensor`**: Converts the edge list into a PyTorch tensor of shape `(2, num_edges)`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Convert Dataset into a List of Graphs**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "for i in range(len(node_features)):\n",
    "    x = torch.tensor(node_features[i], dtype=torch.float)  # Node features for jet i\n",
    "    y = torch.tensor(labels[i], dtype=torch.long)  # Label for jet i\n",
    "    edge_index = create_edge_index(x.shape[0])  # Fully connected graph\n",
    "    graphs.append(Data(x=x, edge_index=edge_index, y=y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. **`graphs`**: A list to store graph representations of each jet.\n",
    "14. **`x`**: Converts the particle features of jet `i` into a PyTorch tensor.\n",
    "15. **`y`**: Converts the label of jet `i` into a PyTorch tensor.\n",
    "16. **`edge_index`**: Creates a fully connected graph for the particles in jet `i`.\n",
    "17. **`Data`**: Combines `x`, `edge_index`, and `y` into a graph object.\n",
    "18. **`graphs.append`**: Adds the graph to the list.\n",
    "\n",
    "---\n",
    "\n",
    "### **Create a DataLoader for Batching**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "loader = DataLoader(graphs, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. **`batch_size`**: Number of graphs (jets) per batch.\n",
    "20. **`DataLoader`**: Handles batching and shuffling of the graphs for training.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Define the GCN Model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)  # Fully connected layer for graph-level classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. **`GCN`**: Defines the Graph Convolutional Network model.\n",
    "22. **`GCNConv`**: Two GCN layers for learning node-level features.\n",
    "23. **`torch.nn.Linear`**: A fully connected layer for graph-level classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)  # Aggregate node features into graph-level features\n",
    "        x = self.fc(x)  # Final classification layer\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. **`forward`**: Defines the forward pass of the model.\n",
    "25. **`data.x`**: Node features.\n",
    "26. **`data.edge_index`**: Graph structure (edges).\n",
    "27. **`data.batch`**: Batch information (which nodes belong to which graph).\n",
    "28. **`global_mean_pool`**: Aggregates node features into a single graph-level feature.\n",
    "29. **`F.log_softmax`**: Outputs probabilities for each class (quark or gluon).\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Initialize the Model, Optimizer, and Loss Function**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 4  # Each particle has 4 features: pt, rapidity, azimuthal angle, pdgid\n",
    "hidden_dim = 64\n",
    "output_dim = 2  # Binary classification: quark (1) or gluon (0)\n",
    "\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30. **`input_dim`**: Number of input features per particle.\n",
    "31. **`hidden_dim`**: Number of hidden units in the GCN layers.\n",
    "32. **`output_dim`**: Number of output classes (binary classification).\n",
    "33. **`Adam`**: Optimizer for training the model.\n",
    "34. **`CrossEntropyLoss`**: Loss function for classification tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Train the Model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)  # Output shape: (batch_size, output_dim)\n",
    "        loss = criterion(out, batch.y)  # batch.y shape: (batch_size,)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35. **`train`**: Defines the training loop.\n",
    "36. **`model.train()`**: Sets the model to training mode.\n",
    "37. **`optimizer.zero_grad()`**: Clears gradients from the previous step.\n",
    "38. **`model(batch)`**: Runs the forward pass for the batch.\n",
    "39. **`loss.backward()`**: Computes gradients for the model parameters.\n",
    "40. **`optimizer.step()`**: Updates the model parameters.\n",
    "41. **`total_loss`**: Accumulates the loss for the batch.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 5: Evaluate the Model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in loader:\n",
    "        out = model(batch)\n",
    "        _, pred = out.max(dim=1)\n",
    "        correct += pred.eq(batch.y).sum().item()\n",
    "        total += batch.y.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "42. **`test`**: Defines the evaluation loop.\n",
    "43. **`model.eval()`**: Sets the model to evaluation mode.\n",
    "44. **`out.max(dim=1)`**: Gets the predicted class for each graph.\n",
    "45. **`pred.eq(batch.y)`**: Compares predictions with ground truth labels.\n",
    "46. **`correct`**: Counts the number of correct predictions.\n",
    "47. **`total`**: Tracks the total number of graphs.\n",
    "\n",
    "---\n",
    "\n",
    "### **Training Loop**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):  # Reduce epochs for testing; increase as needed\n",
    "    loss = train()\n",
    "    acc = test()\n",
    "    print(f'Epoch {epoch}, Loss: {loss:.4f}, Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "48. **`range(20)`**: Runs the training loop for 20 epochs.\n",
    "49. **`train()`**: Trains the model for one epoch.\n",
    "50. **`test()`**: Evaluates the model after each epoch.\n",
    "51. **`print`**: Displays the loss and accuracy for each epoch.\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you need further clarification!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GSOC25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
